{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[1]').appName('demo.com').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Robel-Dell:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[1]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>demo.com</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1fc34723ee0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- employee_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- salary: long (nullable = true)\n",
      " |-- age: long (nullable = true)\n",
      " |-- bonus: long (nullable = true)\n",
      "\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|employee_name|department|state|salary|age|bonus|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "|James        |Sales     |NY   |90000 |34 |10000|\n",
      "|Michael      |Sales     |NY   |86000 |56 |20000|\n",
      "|Robert       |Sales     |CA   |81000 |30 |23000|\n",
      "|Maria        |Finance   |CA   |90000 |24 |23000|\n",
      "+-------------+----------+-----+------+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "simpleData = [(\"James\",\"Sales\",\"NY\",90000,34,10000), \\\n",
    "    (\"Michael\",\"Sales\",\"NY\",86000,56,20000), \\\n",
    "    (\"Robert\",\"Sales\",\"CA\",81000,30,23000), \\\n",
    "    (\"Maria\",\"Finance\",\"CA\",90000,24,23000)]\n",
    "\n",
    "columns = [\"employee_name\",\"department\",\"state\",\"salary\",\"age\",\"bonus\"]\n",
    "# ------Creating data frame Using createDataFrame() function-----\n",
    "df = spark.createDataFrame(data = simpleData, schema = columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id    name       city\n",
      "0  1001   Young  Rego Park\n",
      "1  1002   James      Bronx\n",
      "2  1003  Haseeb    Astoria\n",
      "root\n",
      " |-- id: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n",
      "+----+------+---------+\n",
      "|  id|  name|     city|\n",
      "+----+------+---------+\n",
      "|1001| Young|Rego Park|\n",
      "|1002| James|    Bronx|\n",
      "|1003|Haseeb|  Astoria|\n",
      "+----+------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "student_dict = {\"id\": [1001, 1002, 1003],\"name\": [ \"Young\", \"James\", \"Haseeb\"],\"city\": [ \"Rego Park\", \"Bronx\", \"Astoria\"]}\n",
    "\n",
    "# --- panda dataframe ----\n",
    "pd_df = pd.DataFrame(student_dict)\n",
    "print(pd_df)\n",
    "\n",
    "\n",
    "# ----- SparkSQL dataframe-----\n",
    "sp_df = spark.createDataFrame(pd_df)\n",
    "sp_df.printSchema()\n",
    "sp_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- MLS: integer (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Bedrooms: integer (nullable = true)\n",
      " |-- Bathrooms: integer (nullable = true)\n",
      " |-- Size: integer (nullable = true)\n",
      " |-- Price SQ Ft: double (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      "\n",
      "+------+------------------+--------+--------+---------+----+-----------+----------+\n",
      "|   MLS|          Location|   Price|Bedrooms|Bathrooms|Size|Price SQ Ft|    Status|\n",
      "+------+------------------+--------+--------+---------+----+-----------+----------+\n",
      "|132842|     Arroyo Grande|795000.0|       3|        3|2371|      335.3|Short Sale|\n",
      "|134364|       Paso Robles|399000.0|       4|        3|2818|     141.59|Short Sale|\n",
      "|135141|       Paso Robles|545000.0|       4|        3|3032|     179.75|Short Sale|\n",
      "|135712|         Morro Bay|909000.0|       4|        4|3540|     256.78|Short Sale|\n",
      "|136282|Santa Maria-Orcutt|109900.0|       3|        1|1249|      87.99|Short Sale|\n",
      "|136431|            Oceano|324900.0|       3|        3|1800|      180.5|Short Sale|\n",
      "|137036|Santa Maria-Orcutt|192900.0|       4|        2|1603|     120.34|Short Sale|\n",
      "|137090|Santa Maria-Orcutt|215000.0|       3|        2|1450|     148.28|Short Sale|\n",
      "|137159|         Morro Bay|999000.0|       4|        3|3360|     297.32|Short Sale|\n",
      "|137570|        Atascadero|319000.0|       3|        2|1323|     241.12|Short Sale|\n",
      "|138053|Santa Maria-Orcutt|350000.0|       3|        2|1750|      200.0|Short Sale|\n",
      "|138730|Santa Maria-Orcutt|249000.0|       3|        2|1400|     177.86|Short Sale|\n",
      "|139291|     Arroyo Grande|299000.0|       2|        2|1257|     237.87|Short Sale|\n",
      "|139427|Santa Maria-Orcutt|235900.0|       3|        2|1400|      168.5|Short Sale|\n",
      "|139461|Santa Maria-Orcutt|348000.0|       3|        2|1600|      217.5|Short Sale|\n",
      "|139661|       Paso Robles|314000.0|       4|        3|1794|     175.03|Short Sale|\n",
      "|139918|        Los Alamos|399000.0|       4|        2|1850|     215.68|Short Sale|\n",
      "|139932|        San Miguel|599000.0|       3|        3|2950|     203.05|Short Sale|\n",
      "|140044|       Paso Robles|299000.0|       3|        2|1719|     173.94|Short Sale|\n",
      "|140073|   San Luis Obispo|425000.0|       3|        3|1472|     288.72|Short Sale|\n",
      "+------+------------------+--------+--------+---------+----+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Sparkapplicationdemo').getOrCreate()\n",
    "df = spark.read.load(\"C:/PE/RealEstate.csv\", format=\"csv\", header = True, inferSchema = True)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- City: string (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Decommisioned: boolean (nullable = true)\n",
      " |-- EstimatedPopulation: long (nullable = true)\n",
      " |-- Lat: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- LocationText: string (nullable = true)\n",
      " |-- LocationType: string (nullable = true)\n",
      " |-- Long: double (nullable = true)\n",
      " |-- Notes: string (nullable = true)\n",
      " |-- RecordNumber: long (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- TaxReturnsFiled: long (nullable = true)\n",
      " |-- TotalWages: long (nullable = true)\n",
      " |-- WorldRegion: string (nullable = true)\n",
      " |-- Xaxis: double (nullable = true)\n",
      " |-- Yaxis: double (nullable = true)\n",
      " |-- Zaxis: double (nullable = true)\n",
      " |-- ZipCodeType: string (nullable = true)\n",
      " |-- Zipcode: long (nullable = true)\n",
      "\n",
      "+-------------------+-------+-------------+-------------------+-----+--------------------+--------------------+--------------+-------+-------------+------------+-----+---------------+----------+-----------+-----+-----+-----+-----------+-------+\n",
      "|               City|Country|Decommisioned|EstimatedPopulation|  Lat|            Location|        LocationText|  LocationType|   Long|        Notes|RecordNumber|State|TaxReturnsFiled|TotalWages|WorldRegion|Xaxis|Yaxis|Zaxis|ZipCodeType|Zipcode|\n",
      "+-------------------+-------+-------------+-------------------+-----+--------------------+--------------------+--------------+-------+-------------+------------+-----+---------------+----------+-----------+-----+-----+-----+-----------+-------+\n",
      "|        PARC PARQUE|     US|        false|               null|17.96|NA-US-PR-PARC PARQUE|     Parc Parque, PR|NOT ACCEPTABLE| -66.22|         null|           1|   PR|           null|      null|         NA| 0.38|-0.87|  0.3|   STANDARD|    704|\n",
      "|PASEO COSTA DEL SUR|     US|        false|               null|17.96|NA-US-PR-PASEO CO...|Paseo Costa Del S...|NOT ACCEPTABLE| -66.22|         null|           2|   PR|           null|      null|         NA| 0.38|-0.87|  0.3|   STANDARD|    704|\n",
      "|       BDA SAN LUIS|     US|        false|               null|18.14|NA-US-PR-BDA SAN ...|    Bda San Luis, PR|NOT ACCEPTABLE| -66.26|         null|          10|   PR|           null|      null|         NA| 0.38|-0.86| 0.31|   STANDARD|    709|\n",
      "|  CINGULAR WIRELESS|     US|        false|               null|32.72|NA-US-TX-CINGULAR...|Cingular Wireless...|NOT ACCEPTABLE| -97.31|         null|       61391|   TX|           null|      null|         NA| -0.1|-0.83| 0.54|     UNIQUE|  76166|\n",
      "|         FORT WORTH|     US|        false|               4053|32.75| NA-US-TX-FORT WORTH|      Fort Worth, TX|       PRIMARY| -97.33|         null|       61392|   TX|           2126| 122396986|         NA| -0.1|-0.83| 0.54|   STANDARD|  76177|\n",
      "|           FT WORTH|     US|        false|               4053|32.75|   NA-US-TX-FT WORTH|        Ft Worth, TX|    ACCEPTABLE| -97.33|         null|       61393|   TX|           2126| 122396986|         NA| -0.1|-0.83| 0.54|   STANDARD|  76177|\n",
      "|    URB EUGENE RICE|     US|        false|               null|17.96|NA-US-PR-URB EUGE...| Urb Eugene Rice, PR|NOT ACCEPTABLE| -66.22|         null|           4|   PR|           null|      null|         NA| 0.38|-0.87|  0.3|   STANDARD|    704|\n",
      "|               MESA|     US|        false|              26883|33.37|       NA-US-AZ-MESA|            Mesa, AZ|       PRIMARY|-111.64|no NWS data, |       39827|   AZ|          14962| 563792730|         NA| -0.3|-0.77| 0.55|   STANDARD|  85209|\n",
      "|               MESA|     US|        false|              25446|33.38|       NA-US-AZ-MESA|            Mesa, AZ|       PRIMARY|-111.84|         null|       39828|   AZ|          14374| 471000465|         NA|-0.31|-0.77| 0.55|   STANDARD|  85210|\n",
      "|           HILLIARD|     US|        false|               7443|30.69|   NA-US-FL-HILLIARD|        Hilliard, FL|       PRIMARY| -81.92|         null|       49345|   FL|           3922| 133112149|         NA| 0.12|-0.85| 0.51|   STANDARD|  32046|\n",
      "|             HOLDER|     US|        false|               null|28.96|     NA-US-FL-HOLDER|          Holder, FL|       PRIMARY| -82.41|         null|       49346|   FL|           null|      null|         NA| 0.11|-0.86| 0.48|     PO BOX|  34445|\n",
      "|               HOLT|     US|        false|               2190|30.72|       NA-US-FL-HOLT|            Holt, FL|       PRIMARY| -86.67|         null|       49347|   FL|           1207|  36395913|         NA| 0.04|-0.85| 0.51|   STANDARD|  32564|\n",
      "|          HOMOSASSA|     US|        false|               null|28.78|  NA-US-FL-HOMOSASSA|       Homosassa, FL|       PRIMARY| -82.61|         null|       49348|   FL|           null|      null|         NA| 0.11|-0.86| 0.48|     PO BOX|  34487|\n",
      "|       BDA SAN LUIS|     US|        false|               null|18.14|NA-US-PR-BDA SAN ...|    Bda San Luis, PR|NOT ACCEPTABLE| -66.26|         null|          10|   PR|           null|      null|         NA| 0.38|-0.86| 0.31|   STANDARD|    708|\n",
      "|      SECT LANAUSSE|     US|        false|               null|17.96|NA-US-PR-SECT LAN...|   Sect Lanausse, PR|NOT ACCEPTABLE| -66.22|         null|           3|   PR|           null|      null|         NA| 0.38|-0.87|  0.3|   STANDARD|    704|\n",
      "|      SPRING GARDEN|     US|        false|               null|33.97|NA-US-AL-SPRING G...|   Spring Garden, AL|       PRIMARY| -85.55|         null|       54354|   AL|           null|      null|         NA| 0.06|-0.82| 0.55|     PO BOX|  36275|\n",
      "|        SPRINGVILLE|     US|        false|               7845|33.77|NA-US-AL-SPRINGVILLE|     Springville, AL|       PRIMARY| -86.47|         null|       54355|   AL|           4046| 172127599|         NA| 0.05|-0.82| 0.55|   STANDARD|  35146|\n",
      "|        SPRUCE PINE|     US|        false|               1209|34.37|NA-US-AL-SPRUCE PINE|     Spruce Pine, AL|       PRIMARY| -87.69|         null|       54356|   AL|            610|  18525517|         NA| 0.03|-0.82| 0.56|   STANDARD|  35585|\n",
      "|           ASH HILL|     US|        false|               1666| 36.4|   NA-US-NC-ASH HILL|        Ash Hill, NC|NOT ACCEPTABLE| -80.56|         null|       76511|   NC|            842|  28876493|         NA| 0.13|-0.79| 0.59|   STANDARD|  27007|\n",
      "|           ASHEBORO|     US|        false|              15228|35.71|   NA-US-NC-ASHEBORO|        Asheboro, NC|       PRIMARY| -79.81|         null|       76512|   NC|           8355| 215474318|         NA| 0.14|-0.79| 0.58|   STANDARD|  27203|\n",
      "+-------------------+-------+-------------+-------------------+-----+--------------------+--------------------+--------------+-------+-------------+------------+-----+---------------+----------+-----------+-----+-----+-----+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.json(\"C:/PE/zipcode.json\")\n",
    "df.printSchema()\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Test SQL app\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "|orderNumber| orderDate|requiredDate|shippedDate| status|            comments|customerNumber|\n",
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "|      10100|2003-01-06|  2003-01-13| 2003-01-10|Shipped|                null|           363|\n",
      "|      10101|2003-01-09|  2003-01-18| 2003-01-11|Shipped|Check on availabi...|           128|\n",
      "|      10102|2003-01-10|  2003-01-18| 2003-01-14|Shipped|                null|           181|\n",
      "|      10103|2003-01-29|  2003-02-07| 2003-02-02|Shipped|                null|           121|\n",
      "|      10104|2003-01-31|  2003-02-09| 2003-02-01|Shipped|                null|           141|\n",
      "|      10105|2003-02-11|  2003-02-21| 2003-02-12|Shipped|                null|           145|\n",
      "|      10106|2003-02-17|  2003-02-24| 2003-02-21|Shipped|                null|           278|\n",
      "|      10107|2003-02-24|  2003-03-03| 2003-02-26|Shipped|Difficult to nego...|           131|\n",
      "|      10108|2003-03-03|  2003-03-12| 2003-03-08|Shipped|                null|           385|\n",
      "|      10109|2003-03-10|  2003-03-19| 2003-03-11|Shipped|Customer requeste...|           486|\n",
      "|      10110|2003-03-18|  2003-03-24| 2003-03-20|Shipped|                null|           187|\n",
      "|      10111|2003-03-25|  2003-03-31| 2003-03-30|Shipped|                null|           129|\n",
      "|      10112|2003-03-24|  2003-04-03| 2003-03-29|Shipped|Customer requeste...|           144|\n",
      "|      10113|2003-03-26|  2003-04-02| 2003-03-27|Shipped|                null|           124|\n",
      "|      10114|2003-04-01|  2003-04-07| 2003-04-02|Shipped|                null|           172|\n",
      "|      10115|2003-04-04|  2003-04-12| 2003-04-07|Shipped|                null|           424|\n",
      "|      10116|2003-04-11|  2003-04-19| 2003-04-13|Shipped|                null|           381|\n",
      "|      10117|2003-04-16|  2003-04-24| 2003-04-17|Shipped|                null|           148|\n",
      "|      10118|2003-04-21|  2003-04-29| 2003-04-26|Shipped|Customer has work...|           216|\n",
      "|      10119|2003-04-28|  2003-05-05| 2003-05-02|Shipped|                null|           382|\n",
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df=spark.read.format(\"jdbc\").options(driver=\"com.mysql.cj.jdbc.Driver\",\\\n",
    "#                                      user=\"michaelwschmidt_user\",\\\n",
    "#                                      password=\"password\",\\\n",
    "#                                      url=\"jdbc:mysql://mikey.helioho.st:3306/michaelwschmidt_classicmodels\",\\\n",
    "#                                      dbtable=\"orders\").load()\n",
    "# df.show()\n",
    "\n",
    "\n",
    "df=spark.read.format(\"jdbc\").options(driver=\"com.mysql.cj.jdbc.Driver\",\\\n",
    "                                     user=\"root\",\\\n",
    "                                     password=\"password\",\\\n",
    "                                     url=\"jdbc:mysql://localhost:3306/classicmodels\",\\\n",
    "                                     dbtable=\"classicmodels.orders\").load()\n",
    "df.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+--------+--------+---------+----+-----------+----------+\n",
      "|   MLS|          Location|   Price|Bedrooms|Bathrooms|Size|Price SQ Ft|    Status|\n",
      "+------+------------------+--------+--------+---------+----+-----------+----------+\n",
      "|132842|     Arroyo Grande|795000.0|       3|        3|2371|      335.3|Short Sale|\n",
      "|134364|       Paso Robles|399000.0|       4|        3|2818|     141.59|Short Sale|\n",
      "|135141|       Paso Robles|545000.0|       4|        3|3032|     179.75|Short Sale|\n",
      "|135712|         Morro Bay|909000.0|       4|        4|3540|     256.78|Short Sale|\n",
      "|136282|Santa Maria-Orcutt|109900.0|       3|        1|1249|      87.99|Short Sale|\n",
      "|136431|            Oceano|324900.0|       3|        3|1800|      180.5|Short Sale|\n",
      "|137036|Santa Maria-Orcutt|192900.0|       4|        2|1603|     120.34|Short Sale|\n",
      "|137090|Santa Maria-Orcutt|215000.0|       3|        2|1450|     148.28|Short Sale|\n",
      "+------+------------------+--------+--------+---------+----+-----------+----------+\n",
      "only showing top 8 rows\n",
      "\n",
      "+------+------------------+--------+--------+---------+----+-----------+----------+-----------------+\n",
      "|   MLS|          Location|   Price|Bedrooms|Bathrooms|Size|Price SQ Ft|    Status|PriceAfterService|\n",
      "+------+------------------+--------+--------+---------+----+-----------+----------+-----------------+\n",
      "|132842|     Arroyo Grande|795000.0|       3|        3|2371|      335.3|Short Sale|         796000.0|\n",
      "|134364|       Paso Robles|399000.0|       4|        3|2818|     141.59|Short Sale|         400000.0|\n",
      "|135141|       Paso Robles|545000.0|       4|        3|3032|     179.75|Short Sale|         546000.0|\n",
      "|135712|         Morro Bay|909000.0|       4|        4|3540|     256.78|Short Sale|         910000.0|\n",
      "|136282|Santa Maria-Orcutt|109900.0|       3|        1|1249|      87.99|Short Sale|         110900.0|\n",
      "|136431|            Oceano|324900.0|       3|        3|1800|      180.5|Short Sale|         325900.0|\n",
      "|137036|Santa Maria-Orcutt|192900.0|       4|        2|1603|     120.34|Short Sale|         193900.0|\n",
      "|137090|Santa Maria-Orcutt|215000.0|       3|        2|1450|     148.28|Short Sale|         216000.0|\n",
      "+------+------------------+--------+--------+---------+----+-----------+----------+-----------------+\n",
      "only showing top 8 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Sparkapplicationdemo').getOrCreate()\n",
    "df = spark.read.load(\"C:/PE/RealEstate.csv\", format=\"csv\", header = True,inferSchema = True)\n",
    "df.show(8)\n",
    "new_df= df.withColumn('PriceAfterService', df.Price + 1000)\n",
    "# Checking the Updated DataFrame\n",
    "new_df.show(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType,BooleanType,DoubleType, DateType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([ \\\n",
    "    StructField(\"firstname\",StringType(),True), \\\n",
    "    StructField(\"middlename\",StringType(),True), \\\n",
    "    StructField(\"lastname\",StringType(),True), \\\n",
    "    StructField(\"id\", StringType(), True), \\\n",
    "    StructField(\"gender\", StringType(), True), \\\n",
    "    StructField(\"salary\", IntegerType(), True) \\\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|          Location|\n",
      "+------------------+\n",
      "|     Arroyo Grande|\n",
      "|       Paso Robles|\n",
      "|       Paso Robles|\n",
      "|         Morro Bay|\n",
      "|Santa Maria-Orcutt|\n",
      "|            Oceano|\n",
      "|Santa Maria-Orcutt|\n",
      "|Santa Maria-Orcutt|\n",
      "|         Morro Bay|\n",
      "|        Atascadero|\n",
      "|Santa Maria-Orcutt|\n",
      "|Santa Maria-Orcutt|\n",
      "|     Arroyo Grande|\n",
      "|Santa Maria-Orcutt|\n",
      "|Santa Maria-Orcutt|\n",
      "|       Paso Robles|\n",
      "|        Los Alamos|\n",
      "|        San Miguel|\n",
      "|       Paso Robles|\n",
      "|   San Luis Obispo|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------------------+---------+----------+\n",
      "|          Location|    Price|    Status|\n",
      "+------------------+---------+----------+\n",
      "|     Arroyo Grande| 795000.0|Short Sale|\n",
      "|       Paso Robles| 399000.0|Short Sale|\n",
      "|       Paso Robles| 545000.0|Short Sale|\n",
      "|         Morro Bay| 909000.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 109900.0|Short Sale|\n",
      "|            Oceano| 324900.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 192900.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 215000.0|Short Sale|\n",
      "|         Morro Bay| 999000.0|Short Sale|\n",
      "|        Atascadero| 319000.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 350000.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 249000.0|Short Sale|\n",
      "|     Arroyo Grande| 299000.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 235900.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 348000.0|Short Sale|\n",
      "|       Paso Robles| 314000.0|Short Sale|\n",
      "|        Los Alamos| 399000.0|Short Sale|\n",
      "|        San Miguel| 599000.0|Short Sale|\n",
      "|       Paso Robles| 299000.0|Short Sale|\n",
      "|   San Luis Obispo| 425000.0|Short Sale|\n",
      "|         Morro Bay|1100000.0|Short Sale|\n",
      "|           Cayucos|1500000.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 110000.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 200000.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 134900.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 250000.0|Short Sale|\n",
      "|       Pismo Beach| 950000.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 239950.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 170000.0|Short Sale|\n",
      "|Santa Maria-Orcutt| 285000.0|Short Sale|\n",
      "+------------------+---------+----------+\n",
      "only showing top 30 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Sparkapplicationdemo').getOrCreate()\n",
    "# Reading the Dataset\n",
    "df = spark.read.load(\"C:/PE/RealEstate.csv\", format=\"csv\", header = True,inferSchema = True)\n",
    "#Show all entries in Location column\n",
    "df.select(\"Location\").show(20)\n",
    "\n",
    "#Show all entries in Location, Price, rank, Status columns\n",
    "df.select(\"Location\", \"Price\", \"Status\").show(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "cardf = spark.read.load(\"C:/PE/cars.csv\", format=\"csv\", header = True,inferSchema = True)\n",
    "\n",
    "cardf1 = cardf.withColumn('HW Ratio', cardf['Weight'] / cardf['Horsepower'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+------------------+\n",
      "|                 Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|quantity|   city|          HW Ratio|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+------------------+\n",
      "|AMC Ambassador Br...|13.0|        8|       360.0|       175|  3821|        11.0|   73|    US|      25|NewYork|21.834285714285713|\n",
      "|  AMC Ambassador DPL|15.0|        8|       390.0|       190|  3850|         8.5|   70|    US|       2|     NJ|20.263157894736842|\n",
      "|  AMC Ambassador SST|17.0|        8|       304.0|       150|  3672|        11.5|   72|    US|       4| DALLAS|             24.48|\n",
      "|         AMC Concord|19.4|        6|       232.0|        90|  3210|        17.2|   78|    US|      52|  TEXAS|35.666666666666664|\n",
      "|         AMC Concord|24.3|        4|       151.0|        90|  3003|        20.1|   80|    US|      42|     OH| 33.36666666666667|\n",
      "|     AMC Concord d/l|18.1|        6|       258.0|       120|  3410|        15.1|   78|    US|       4|NewYork|28.416666666666668|\n",
      "|      AMC Concord DL|23.0|        4|       151.0|         0|  3035|        20.5|   82|    US|      45|     NJ|              null|\n",
      "|    AMC Concord DL 6|20.2|        6|       232.0|        90|  3265|        18.2|   79|    US|     328| DALLAS| 36.27777777777778|\n",
      "|         AMC Gremlin|21.0|        6|       199.0|        90|  2648|        15.0|   70|    US|      68|  TEXAS| 29.42222222222222|\n",
      "|         AMC Gremlin|19.0|        6|       232.0|       100|  2634|        13.0|   71|    US|      78|     OH|             26.34|\n",
      "|         AMC Gremlin|18.0|        6|       232.0|       100|  2789|        15.0|   73|    US|     152|NewYork|             27.89|\n",
      "|         AMC Gremlin|20.0|        6|       232.0|       100|  2914|        16.0|   75|    US|     214|     NJ|             29.14|\n",
      "|          AMC Hornet|18.0|        6|       199.0|        97|  2774|        15.5|   70|    US|      60| DALLAS|  28.5979381443299|\n",
      "|          AMC Hornet|18.0|        6|       232.0|       100|  2945|        16.0|   73|    US|     144|  TEXAS|             29.45|\n",
      "|          AMC Hornet|19.0|        6|       232.0|       100|  2901|        16.0|   74|    US|     172|     OH|             29.01|\n",
      "|          AMC Hornet|22.5|        6|       232.0|        90|  3085|        17.6|   76|    US|      28|NewYork| 34.27777777777778|\n",
      "|AMC Hornet Sporta...|18.0|        6|       258.0|       110|  2962|        13.5|   71|    US|      90|     NJ|26.927272727272726|\n",
      "|         AMC Matador|18.0|        6|       232.0|       100|  3288|        15.5|   71|    US|      82| DALLAS|             32.88|\n",
      "|         AMC Matador|14.0|        8|       304.0|       150|  3672|        11.5|   73|    US|     131|  TEXAS|             24.48|\n",
      "|         AMC Matador|16.0|        6|       258.0|       110|  3632|        18.0|   74|    US|     179|NewYork|33.018181818181816|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+\n",
      "|                 Car| MPG|Cylinders|Displacement|Horsepower|Weight|Acceleration|Model|Origin|quantity|   city|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+\n",
      "|AMC Ambassador Br...|13.0|        8|       360.0|       175|  3821|        11.0|   73|    US|      25|NewYork|\n",
      "|  AMC Ambassador DPL|15.0|        8|       390.0|       190|  3850|         8.5|   70|    US|       2|     NJ|\n",
      "|  AMC Ambassador SST|17.0|        8|       304.0|       150|  3672|        11.5|   72|    US|       4| DALLAS|\n",
      "|         AMC Concord|19.4|        6|       232.0|        90|  3210|        17.2|   78|    US|      52|  TEXAS|\n",
      "|         AMC Concord|24.3|        4|       151.0|        90|  3003|        20.1|   80|    US|      42|     OH|\n",
      "|     AMC Concord d/l|18.1|        6|       258.0|       120|  3410|        15.1|   78|    US|       4|NewYork|\n",
      "|      AMC Concord DL|23.0|        4|       151.0|         0|  3035|        20.5|   82|    US|      45|     NJ|\n",
      "|    AMC Concord DL 6|20.2|        6|       232.0|        90|  3265|        18.2|   79|    US|     328| DALLAS|\n",
      "|         AMC Gremlin|21.0|        6|       199.0|        90|  2648|        15.0|   70|    US|      68|  TEXAS|\n",
      "|         AMC Gremlin|19.0|        6|       232.0|       100|  2634|        13.0|   71|    US|      78|     OH|\n",
      "|         AMC Gremlin|18.0|        6|       232.0|       100|  2789|        15.0|   73|    US|     152|NewYork|\n",
      "|         AMC Gremlin|20.0|        6|       232.0|       100|  2914|        16.0|   75|    US|     214|     NJ|\n",
      "|          AMC Hornet|18.0|        6|       199.0|        97|  2774|        15.5|   70|    US|      60| DALLAS|\n",
      "|          AMC Hornet|18.0|        6|       232.0|       100|  2945|        16.0|   73|    US|     144|  TEXAS|\n",
      "|          AMC Hornet|19.0|        6|       232.0|       100|  2901|        16.0|   74|    US|     172|     OH|\n",
      "|          AMC Hornet|22.5|        6|       232.0|        90|  3085|        17.6|   76|    US|      28|NewYork|\n",
      "|AMC Hornet Sporta...|18.0|        6|       258.0|       110|  2962|        13.5|   71|    US|      90|     NJ|\n",
      "|         AMC Matador|18.0|        6|       232.0|       100|  3288|        15.5|   71|    US|      82| DALLAS|\n",
      "|         AMC Matador|14.0|        8|       304.0|       150|  3672|        11.5|   73|    US|     131|  TEXAS|\n",
      "|         AMC Matador|16.0|        6|       258.0|       110|  3632|        18.0|   74|    US|     179|NewYork|\n",
      "+--------------------+----+---------+------------+----------+------+------------+-----+------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cardf1.show()\n",
    "cardf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+\n",
      "|      Location|        avg(Price)|\n",
      "+--------------+------------------+\n",
      "|   Pismo Beach| 772374.5833333334|\n",
      "|     King City|          131190.0|\n",
      "|    New Cuyama|           40900.0|\n",
      "|        Nipomo| 454166.6666666667|\n",
      "|        Oceano|          392640.0|\n",
      "|        Nipomo| 430629.4117647059|\n",
      "|     Templeton| 705890.9090909091|\n",
      "| Arroyo Grande|1013958.3333333334|\n",
      "|   Bakersfield|           91500.0|\n",
      "|     Guadalupe|          117250.0|\n",
      "+--------------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Sparkapplicationdemo').getOrCreate()\n",
    "# Reading the Dataset\n",
    "df = spark.read.load(\"C:/PE/RealEstate.csv\", format=\"csv\", header = True,inferSchema = True)\n",
    "\n",
    "df.select(\"Location\", \"Price\").groupby(\"Location\").avg().show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
